{"cells":[{"metadata":{"_uuid":"f71f0413-9392-4999-b624-c1c360ad6f27","_cell_guid":"053e8650-b8eb-4cc2-8275-741f11949626","trusted":true},"cell_type":"code","source":"!git clone https://gitlab.com/matthieu_futeral/birds_classification bird_classification\n%cd bird_classification","execution_count":8,"outputs":[{"output_type":"stream","text":"Cloning into 'bird_classification'...\nwarning: redirecting to https://gitlab.com/matthieu_futeral/birds_classification.git/\nremote: Enumerating objects: 164, done.\u001b[K\nremote: Counting objects: 100% (164/164), done.\u001b[K\nremote: Compressing objects: 100% (71/71), done.\u001b[K\nremote: Total 164 (delta 93), reused 134 (delta 69), pack-reused 0\u001b[K\nReceiving objects: 100% (164/164), 125.84 MiB | 23.89 MiB/s, done.\nResolving deltas: 100% (93/93), done.\n/kaggle/working/bird_classification\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/facebookresearch/detectron2.git detectron2\n!git clone https://github.com/dongheehand/SRGAN-PyTorch.git SRGAN","execution_count":2,"outputs":[{"output_type":"stream","text":"Cloning into 'detectron2'...\nremote: Enumerating objects: 40, done.\u001b[K\nremote: Counting objects: 100% (40/40), done.\u001b[K\nremote: Compressing objects: 100% (33/33), done.\u001b[K\nremote: Total 8874 (delta 10), reused 16 (delta 7), pack-reused 8834\u001b[K\nReceiving objects: 100% (8874/8874), 3.68 MiB | 8.25 MiB/s, done.\nResolving deltas: 100% (6433/6433), done.\nCloning into 'SRGAN'...\nremote: Enumerating objects: 90, done.\u001b[K\nremote: Counting objects: 100% (90/90), done.\u001b[K\nremote: Compressing objects: 100% (83/83), done.\u001b[K\nremote: Total 90 (delta 10), reused 86 (delta 7), pack-reused 0\u001b[K\nUnpacking objects: 100% (90/90), done.\n","name":"stdout"}]},{"metadata":{"_uuid":"06daed48-9636-4aa6-9d13-10b70628cec2","_cell_guid":"3977e7e0-5383-41fd-b098-bcc784da3789","trusted":true},"cell_type":"code","source":"from distutils.dir_util import copy_tree\ncopy_tree(\"/kaggle/input/cropped-birds\", \"/kaggle/working/bird_classification/\")\n#copy_tree(\"/kaggle/input/cropped-nabirds\", \"/kaggle/working/bird_classification/\")\ncopy_tree(\"/kaggle/input/confident-filtered-cropped-nabirds\", \"/kaggle/working/bird_classification/\")\ncopy_tree(\"/kaggle/input/experiment\", \"/kaggle/working/bird_classification/\")\ncopy_tree(\"/kaggle/input/early-stopping\", \"/kaggle/working/bird_classification/\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"['/kaggle/working/bird_classification/early_stopping/requirements.txt',\n '/kaggle/working/bird_classification/early_stopping/.git',\n '/kaggle/working/bird_classification/early_stopping/loss_plot.png',\n '/kaggle/working/bird_classification/early_stopping/.gitignore',\n '/kaggle/working/bird_classification/early_stopping/CODE_OF_CONDUCT.md',\n '/kaggle/working/bird_classification/early_stopping/MNIST_Early_Stopping_example.ipynb',\n '/kaggle/working/bird_classification/early_stopping/checkpoint.pt',\n '/kaggle/working/bird_classification/early_stopping/pytorchtools.py',\n '/kaggle/working/bird_classification/early_stopping/LICENSE',\n '/kaggle/working/bird_classification/early_stopping/README.md']"},"metadata":{}}]},{"metadata":{"_uuid":"690c3e83-462c-4605-b258-6fccbf94dca5","_cell_guid":"7f0fa745-6ce5-43e4-90e5-1fd1d3195c8e","trusted":true},"cell_type":"code","source":"%pip install logger\n%pip install numpy\n%pip install torch\n%pip install torchvision\n%pip install tqdm\n%pip install timm\n%pip install tensorboard","execution_count":10,"outputs":[{"output_type":"stream","text":"Collecting logger\n  Downloading logger-1.4.tar.gz (1.2 kB)\nBuilding wheels for collected packages: logger\n  Building wheel for logger (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for logger: filename=logger-1.4-py3-none-any.whl size=1789 sha256=4cfb30310dd4921799245266d2e9a0fab372915a7541559531b4df80a2d774df\n  Stored in directory: /root/.cache/pip/wheels/04/00/65/435977d12c4daa4fd57668863c0a3e89d041d5d39227a8b774\nSuccessfully built logger\nInstalling collected packages: logger\nSuccessfully installed logger-1.4\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.18.5)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.6.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch) (1.18.5)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.7.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.18.5)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.6.0)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.0.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision) (0.18.2)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.45.0)\nNote: you may need to restart the kernel to use updated packages.\nCollecting timm\n  Downloading timm-0.3.1-py3-none-any.whl (247 kB)\n\u001b[K     |████████████████████████████████| 247 kB 884 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.7.0)\nRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm) (1.6.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.18.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.0.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (0.18.2)\nInstalling collected packages: timm\nSuccessfully installed timm-0.3.1\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (2.3.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.14.0)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.33.2)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.18.5)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.4.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.14.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.13.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.0.1)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.34.2)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.11.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (46.1.3.post20200325)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.2.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.7.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.23.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.2.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.1.1)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.7)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.0.1)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"_uuid":"f5f2c1d7-204b-4d63-b573-1a726ef2dc2c","_cell_guid":"d63b77f8-1445-4edc-a3cd-cc92a7d9a66c","trusted":true},"cell_type":"code","source":"# Run .py files here\n%run pseudo_labelling.py --RUN_ID 31d84 --model vit --batch_size 8 --epochs 50 --patience 5 --lr 1e-5 --weight_decay 1e-4 --dropout 0.25 --cfg vit_large_patch16_224 \\\n                         --horizontal_flip 1 --vertical_flip 1 --random_rotation 0 --erasing 0 --size 224 --accumulation_steps 1 --n_split 150 --threshold 0.98 --strong_augmentation 1 \\\n                         --T2 10 --factor 2 --prob 0.75","execution_count":null,"outputs":[{"output_type":"stream","text":"Pseudo Labelling\nRUN_ID : 1c1e9\n[16/Nov/2020 22:23:16] INFO - vit model loaded\nUsing GPU\n[16/Nov/2020 22:23:27] INFO - Epoch 1 - Start TRAINING\n","name":"stdout"},{"output_type":"stream","text":"/kaggle/working/bird_classification/pseudo_labelling.py:45: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  for batch_idx in tqdm_notebook(range(n_batches)):\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c99fd9f0af64102b7276f70d1a4eed6"}},"metadata":{}},{"output_type":"stream","text":"[16/Nov/2020 22:23:30] INFO - Unlabeled Train Epoch: 1 [0/2166 (0%)]\t Average Loss: 0.016384\nUnlabeled examples trained on : 7\n[16/Nov/2020 22:23:38] INFO - Unlabeled Train Epoch: 1 [80/2166 (4%)]\t Average Loss: 0.000313\nUnlabeled examples trained on : 52\n[16/Nov/2020 22:23:47] INFO - Unlabeled Train Epoch: 1 [160/2166 (7%)]\t Average Loss: 0.001279\nUnlabeled examples trained on : 110\n[16/Nov/2020 22:24:12] INFO - Unlabeled Train Epoch: 1 [400/2166 (18%)]\t Average Loss: 0.000442\nUnlabeled examples trained on : 261\n[16/Nov/2020 22:24:20] INFO - Unlabeled Train Epoch: 1 [480/2166 (22%)]\t Average Loss: 0.001407\nUnlabeled examples trained on : 303\n[16/Nov/2020 22:24:29] INFO - Unlabeled Train Epoch: 1 [560/2166 (26%)]\t Average Loss: 0.000125\nUnlabeled examples trained on : 367\n[16/Nov/2020 22:24:37] INFO - Unlabeled Train Epoch: 1 [640/2166 (30%)]\t Average Loss: 0.005167\nUnlabeled examples trained on : 414\n[16/Nov/2020 22:24:46] INFO - Unlabeled Train Epoch: 1 [720/2166 (33%)]\t Average Loss: 0.000217\nUnlabeled examples trained on : 467\n[16/Nov/2020 22:24:55] INFO - Unlabeled Train Epoch: 1 [800/2166 (37%)]\t Average Loss: 0.000154\nUnlabeled examples trained on : 530\n[16/Nov/2020 22:25:03] INFO - Unlabeled Train Epoch: 1 [880/2166 (41%)]\t Average Loss: 0.001543\nUnlabeled examples trained on : 584\n[16/Nov/2020 22:25:11] INFO - Unlabeled Train Epoch: 1 [960/2166 (44%)]\t Average Loss: 0.000560\nUnlabeled examples trained on : 624\n[16/Nov/2020 22:25:27] INFO - Unlabeled Train Epoch: 1 [1120/2166 (52%)]\t Average Loss: 0.000214\nUnlabeled examples trained on : 714\n[16/Nov/2020 22:25:35] INFO - Unlabeled Train Epoch: 1 [1200/2166 (55%)]\t Average Loss: 0.003306\nUnlabeled examples trained on : 743\n[16/Nov/2020 22:25:44] INFO - Unlabeled Train Epoch: 1 [1280/2166 (59%)]\t Average Loss: 0.000663\nUnlabeled examples trained on : 791\n[16/Nov/2020 22:25:52] INFO - Unlabeled Train Epoch: 1 [1360/2166 (63%)]\t Average Loss: 0.000965\nUnlabeled examples trained on : 829\n[16/Nov/2020 22:26:24] INFO - Unlabeled Train Epoch: 1 [1680/2166 (77%)]\t Average Loss: 0.000393\nUnlabeled examples trained on : 1005\n[16/Nov/2020 22:26:33] INFO - Unlabeled Train Epoch: 1 [1760/2166 (81%)]\t Average Loss: 0.000090\nUnlabeled examples trained on : 1052\n[16/Nov/2020 22:26:41] INFO - Unlabeled Train Epoch: 1 [1840/2166 (85%)]\t Average Loss: 0.005314\nUnlabeled examples trained on : 1107\n[16/Nov/2020 22:26:49] INFO - Unlabeled Train Epoch: 1 [1920/2166 (89%)]\t Average Loss: 0.002095\nUnlabeled examples trained on : 1150\n[16/Nov/2020 22:26:58] INFO - Unlabeled Train Epoch: 1 [2000/2166 (92%)]\t Average Loss: 0.009685\nUnlabeled examples trained on : 1209\n[16/Nov/2020 22:27:06] INFO - Unlabeled Train Epoch: 1 [2080/2166 (96%)]\t Average Loss: 0.000605\nUnlabeled examples trained on : 1251\n[16/Nov/2020 22:27:39] INFO - Unlabeled Train Epoch: 1 [2400/2166 (111%)]\t Average Loss: 0.000158\nUnlabeled examples trained on : 1457\n[16/Nov/2020 22:27:48] INFO - Unlabeled Train Epoch: 1 [2480/2166 (114%)]\t Average Loss: 0.000052\nUnlabeled examples trained on : 1516\n[16/Nov/2020 22:27:56] INFO - Unlabeled Train Epoch: 1 [2560/2166 (118%)]\t Average Loss: 0.000836\nUnlabeled examples trained on : 1566\n[16/Nov/2020 22:28:05] INFO - Unlabeled Train Epoch: 1 [2640/2166 (122%)]\t Average Loss: 0.000362\nUnlabeled examples trained on : 1616\n[16/Nov/2020 22:28:13] INFO - Unlabeled Train Epoch: 1 [2720/2166 (125%)]\t Average Loss: 0.052781\nUnlabeled examples trained on : 1684\n[16/Nov/2020 22:28:29] INFO - Unlabeled Train Epoch: 1 [2880/2166 (133%)]\t Average Loss: 0.000079\nUnlabeled examples trained on : 1760\n[16/Nov/2020 22:28:38] INFO - Unlabeled Train Epoch: 1 [2960/2166 (137%)]\t Average Loss: 0.000224\nUnlabeled examples trained on : 1813\n[16/Nov/2020 22:28:55] INFO - Unlabeled Train Epoch: 1 [3120/2166 (144%)]\t Average Loss: 0.000289\nUnlabeled examples trained on : 1925\n\n\n\n[16/Nov/2020 22:29:02] INFO - Unlabeled Sample = 1975 out of 2166\n[16/Nov/2020 22:29:02] INFO - Unlabeled Train loss Epoch 1 : 0.0043924577673349835\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 22/22 [00:03<00:00,  5.66it/s]","name":"stderr"},{"output_type":"stream","text":"[16/Nov/2020 22:29:06] INFO - \nValidation set: Average loss: 0.0355, Accuracy: 162/176 (92%)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Validation loss decreased (inf --> 0.035529).  Saving model ...\n[16/Nov/2020 22:29:10] INFO - Epoch 1 - Time elapsed : 343.11139583587646\n[16/Nov/2020 22:29:10] INFO - Epoch 2 - Start TRAINING\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2b7771c138d47caa18b2795e628d3fe"}},"metadata":{}},{"output_type":"stream","text":"[16/Nov/2020 22:29:11] INFO - Unlabeled Train Epoch: 2 [0/2166 (0%)]\t Average Loss: 0.000361\nUnlabeled examples trained on : 6\n[16/Nov/2020 22:29:20] INFO - Unlabeled Train Epoch: 2 [80/2166 (4%)]\t Average Loss: 0.000238\nUnlabeled examples trained on : 65\n[16/Nov/2020 22:29:29] INFO - Unlabeled Train Epoch: 2 [160/2166 (7%)]\t Average Loss: 0.013591\nUnlabeled examples trained on : 122\n[16/Nov/2020 22:29:46] INFO - Unlabeled Train Epoch: 2 [320/2166 (15%)]\t Average Loss: 0.000274\nUnlabeled examples trained on : 213\n[16/Nov/2020 22:29:53] INFO - Unlabeled Train Epoch: 2 [400/2166 (18%)]\t Average Loss: 0.000130\nUnlabeled examples trained on : 252\n[16/Nov/2020 22:30:02] INFO - Unlabeled Train Epoch: 2 [480/2166 (22%)]\t Average Loss: 0.000955\nUnlabeled examples trained on : 319\n[16/Nov/2020 22:30:11] INFO - Unlabeled Train Epoch: 2 [560/2166 (26%)]\t Average Loss: 0.000187\nUnlabeled examples trained on : 384\n[16/Nov/2020 22:30:20] INFO - Unlabeled Train Epoch: 2 [640/2166 (30%)]\t Average Loss: 0.006780\nUnlabeled examples trained on : 447\n[16/Nov/2020 22:30:29] INFO - Unlabeled Train Epoch: 2 [720/2166 (33%)]\t Average Loss: 0.016218\nUnlabeled examples trained on : 504\n[16/Nov/2020 22:30:37] INFO - Unlabeled Train Epoch: 2 [800/2166 (37%)]\t Average Loss: 0.000175\nUnlabeled examples trained on : 557\n[16/Nov/2020 22:30:46] INFO - Unlabeled Train Epoch: 2 [880/2166 (41%)]\t Average Loss: 0.000147\nUnlabeled examples trained on : 623\n[16/Nov/2020 22:30:55] INFO - Unlabeled Train Epoch: 2 [960/2166 (44%)]\t Average Loss: 0.000330\nUnlabeled examples trained on : 674\n[16/Nov/2020 22:31:03] INFO - Unlabeled Train Epoch: 2 [1040/2166 (48%)]\t Average Loss: 0.000078\nUnlabeled examples trained on : 718\n[16/Nov/2020 22:31:20] INFO - Unlabeled Train Epoch: 2 [1200/2166 (55%)]\t Average Loss: 0.000620\nUnlabeled examples trained on : 807\n[16/Nov/2020 22:31:28] INFO - Unlabeled Train Epoch: 2 [1280/2166 (59%)]\t Average Loss: 0.000095\nUnlabeled examples trained on : 856\n[16/Nov/2020 22:31:36] INFO - Unlabeled Train Epoch: 2 [1360/2166 (63%)]\t Average Loss: 0.000079\nUnlabeled examples trained on : 916\n[16/Nov/2020 22:31:45] INFO - Unlabeled Train Epoch: 2 [1440/2166 (66%)]\t Average Loss: 0.000674\nUnlabeled examples trained on : 958\n[16/Nov/2020 22:31:53] INFO - Unlabeled Train Epoch: 2 [1520/2166 (70%)]\t Average Loss: 0.000159\nUnlabeled examples trained on : 1008\n[16/Nov/2020 22:32:02] INFO - Unlabeled Train Epoch: 2 [1600/2166 (74%)]\t Average Loss: 0.000371\nUnlabeled examples trained on : 1068\n[16/Nov/2020 22:32:10] INFO - Unlabeled Train Epoch: 2 [1680/2166 (77%)]\t Average Loss: 0.020622\nUnlabeled examples trained on : 1114\n[16/Nov/2020 22:32:18] INFO - Unlabeled Train Epoch: 2 [1760/2166 (81%)]\t Average Loss: 0.000431\nUnlabeled examples trained on : 1164\n[16/Nov/2020 22:32:27] INFO - Unlabeled Train Epoch: 2 [1840/2166 (85%)]\t Average Loss: 0.003122\nUnlabeled examples trained on : 1215\n[16/Nov/2020 22:32:36] INFO - Unlabeled Train Epoch: 2 [1920/2166 (89%)]\t Average Loss: 0.000170\nUnlabeled examples trained on : 1272\n[16/Nov/2020 22:32:53] INFO - Unlabeled Train Epoch: 2 [2080/2166 (96%)]\t Average Loss: 0.002797\nUnlabeled examples trained on : 1383\n[16/Nov/2020 22:33:01] INFO - Unlabeled Train Epoch: 2 [2160/2166 (100%)]\t Average Loss: 0.000456\nUnlabeled examples trained on : 1436\n[16/Nov/2020 22:33:09] INFO - Unlabeled Train Epoch: 2 [2240/2166 (103%)]\t Average Loss: 0.011893\nUnlabeled examples trained on : 1473\n[16/Nov/2020 22:33:17] INFO - Unlabeled Train Epoch: 2 [2320/2166 (107%)]\t Average Loss: 0.000116\nUnlabeled examples trained on : 1512\n[16/Nov/2020 22:33:26] INFO - Unlabeled Train Epoch: 2 [2400/2166 (111%)]\t Average Loss: 0.000668\nUnlabeled examples trained on : 1584\n[16/Nov/2020 22:33:36] INFO - Unlabeled Train Epoch: 2 [2480/2166 (114%)]\t Average Loss: 0.000057\nUnlabeled examples trained on : 1653\n[16/Nov/2020 22:34:01] INFO - Unlabeled Train Epoch: 2 [2720/2166 (125%)]\t Average Loss: 0.000286\nUnlabeled examples trained on : 1782\n[16/Nov/2020 22:34:09] INFO - Unlabeled Train Epoch: 2 [2800/2166 (129%)]\t Average Loss: 0.001379\nUnlabeled examples trained on : 1847\n[16/Nov/2020 22:34:35] INFO - Unlabeled Train Epoch: 2 [3040/2166 (140%)]\t Average Loss: 0.000152\nUnlabeled examples trained on : 2013\n[16/Nov/2020 22:34:43] INFO - Unlabeled Train Epoch: 2 [3120/2166 (144%)]\t Average Loss: 0.007247\nUnlabeled examples trained on : 2058\n\n\n\n[16/Nov/2020 22:34:51] INFO - Unlabeled Sample = 2102 out of 2166\n[16/Nov/2020 22:34:51] INFO - Unlabeled Train loss Epoch 2 : 0.0067467162987047075\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 22/22 [00:03<00:00,  5.77it/s]","name":"stderr"},{"output_type":"stream","text":"[16/Nov/2020 22:34:55] INFO - \nValidation set: Average loss: 0.0286, Accuracy: 164/176 (93%)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Validation loss decreased (0.035529 --> 0.028636).  Saving model ...\n[16/Nov/2020 22:35:00] INFO - Epoch 2 - Time elapsed : 349.39943051338196\n[16/Nov/2020 22:35:00] INFO - Epoch 3 - Start TRAINING\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac6ff2aa7dbd416ea958668cd665689d"}},"metadata":{}},{"output_type":"stream","text":"[16/Nov/2020 22:35:14] INFO - Unlabeled Train Epoch: 3 [80/2166 (4%)]\t Average Loss: 0.000427\nUnlabeled examples trained on : 61\n[16/Nov/2020 22:35:30] INFO - Unlabeled Train Epoch: 3 [240/2166 (11%)]\t Average Loss: 0.001830\nUnlabeled examples trained on : 155\n[16/Nov/2020 22:35:39] INFO - Unlabeled Train Epoch: 3 [320/2166 (15%)]\t Average Loss: 0.001982\nUnlabeled examples trained on : 198\n[16/Nov/2020 22:35:47] INFO - Unlabeled Train Epoch: 3 [400/2166 (18%)]\t Average Loss: 0.000179\nUnlabeled examples trained on : 257\n[16/Nov/2020 22:35:56] INFO - Unlabeled Train Epoch: 3 [480/2166 (22%)]\t Average Loss: 0.015194\nUnlabeled examples trained on : 315\n[16/Nov/2020 22:36:22] INFO - Unlabeled Train Epoch: 3 [720/2166 (33%)]\t Average Loss: 0.000414\nUnlabeled examples trained on : 500\n[16/Nov/2020 22:36:31] INFO - Unlabeled Train Epoch: 3 [800/2166 (37%)]\t Average Loss: 0.000054\nUnlabeled examples trained on : 563\n[16/Nov/2020 22:36:39] INFO - Unlabeled Train Epoch: 3 [880/2166 (41%)]\t Average Loss: 0.000128\nUnlabeled examples trained on : 600\n[16/Nov/2020 22:36:47] INFO - Unlabeled Train Epoch: 3 [960/2166 (44%)]\t Average Loss: 0.000240\nUnlabeled examples trained on : 638\n[16/Nov/2020 22:37:03] INFO - Unlabeled Train Epoch: 3 [1120/2166 (52%)]\t Average Loss: 0.001693\nUnlabeled examples trained on : 734\n[16/Nov/2020 22:37:21] INFO - Unlabeled Train Epoch: 3 [1280/2166 (59%)]\t Average Loss: 0.055018\nUnlabeled examples trained on : 846\n[16/Nov/2020 22:37:29] INFO - Unlabeled Train Epoch: 3 [1360/2166 (63%)]\t Average Loss: 0.000151\nUnlabeled examples trained on : 891\n[16/Nov/2020 22:37:38] INFO - Unlabeled Train Epoch: 3 [1440/2166 (66%)]\t Average Loss: 0.000145\nUnlabeled examples trained on : 958\n[16/Nov/2020 22:37:55] INFO - Unlabeled Train Epoch: 3 [1600/2166 (74%)]\t Average Loss: 0.000656\nUnlabeled examples trained on : 1070\n[16/Nov/2020 22:38:04] INFO - Unlabeled Train Epoch: 3 [1680/2166 (77%)]\t Average Loss: 0.044977\nUnlabeled examples trained on : 1138\n[16/Nov/2020 22:38:12] INFO - Unlabeled Train Epoch: 3 [1760/2166 (81%)]\t Average Loss: 0.000460\nUnlabeled examples trained on : 1189\n[16/Nov/2020 22:38:21] INFO - Unlabeled Train Epoch: 3 [1840/2166 (85%)]\t Average Loss: 0.000054\nUnlabeled examples trained on : 1235\n[16/Nov/2020 22:38:30] INFO - Unlabeled Train Epoch: 3 [1920/2166 (89%)]\t Average Loss: 0.000078\nUnlabeled examples trained on : 1309\n[16/Nov/2020 22:38:39] INFO - Unlabeled Train Epoch: 3 [2000/2166 (92%)]\t Average Loss: 0.001041\nUnlabeled examples trained on : 1375\n[16/Nov/2020 22:38:56] INFO - Unlabeled Train Epoch: 3 [2160/2166 (100%)]\t Average Loss: 0.000126\nUnlabeled examples trained on : 1497\n[16/Nov/2020 22:39:04] INFO - Unlabeled Train Epoch: 3 [2240/2166 (103%)]\t Average Loss: 0.000035\nUnlabeled examples trained on : 1544\n[16/Nov/2020 22:39:21] INFO - Unlabeled Train Epoch: 3 [2400/2166 (111%)]\t Average Loss: 0.000057\nUnlabeled examples trained on : 1651\n[16/Nov/2020 22:39:29] INFO - Unlabeled Train Epoch: 3 [2480/2166 (114%)]\t Average Loss: 0.007645\nUnlabeled examples trained on : 1696\n[16/Nov/2020 22:39:38] INFO - Unlabeled Train Epoch: 3 [2560/2166 (118%)]\t Average Loss: 0.000164\nUnlabeled examples trained on : 1757\n[16/Nov/2020 22:39:47] INFO - Unlabeled Train Epoch: 3 [2640/2166 (122%)]\t Average Loss: 0.000226\nUnlabeled examples trained on : 1807\n[16/Nov/2020 22:40:03] INFO - Unlabeled Train Epoch: 3 [2800/2166 (129%)]\t Average Loss: 0.000077\nUnlabeled examples trained on : 1914\n[16/Nov/2020 22:40:12] INFO - Unlabeled Train Epoch: 3 [2880/2166 (133%)]\t Average Loss: 0.000166\nUnlabeled examples trained on : 1988\n[16/Nov/2020 22:40:21] INFO - Unlabeled Train Epoch: 3 [2960/2166 (137%)]\t Average Loss: 0.000165\nUnlabeled examples trained on : 2048\n[16/Nov/2020 22:40:38] INFO - Unlabeled Train Epoch: 3 [3120/2166 (144%)]\t Average Loss: 0.000118\nUnlabeled examples trained on : 2165\n\n\n\n[16/Nov/2020 22:40:46] INFO - Unlabeled Sample = 2229 out of 2166\n[16/Nov/2020 22:40:46] INFO - Unlabeled Train loss Epoch 3 : 0.007830785019424961\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 22/22 [00:03<00:00,  5.75it/s]","name":"stderr"},{"output_type":"stream","text":"[16/Nov/2020 22:40:50] INFO - \nValidation set: Average loss: 0.0275, Accuracy: 163/176 (93%)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Validation loss decreased (0.028636 --> 0.027529).  Saving model ...\n[16/Nov/2020 22:40:55] INFO - Epoch 3 - Time elapsed : 355.1724226474762\n[16/Nov/2020 22:40:55] INFO - Epoch 4 - Start TRAINING\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"610c1833bc6a45f19ca338c9302c6b1a"}},"metadata":{}},{"output_type":"stream","text":"[16/Nov/2020 22:40:56] INFO - Unlabeled Train Epoch: 4 [0/2166 (0%)]\t Average Loss: 0.007645\nUnlabeled examples trained on : 8\n[16/Nov/2020 22:41:05] INFO - Unlabeled Train Epoch: 4 [80/2166 (4%)]\t Average Loss: 0.006980\nUnlabeled examples trained on : 81\n[16/Nov/2020 22:41:13] INFO - Unlabeled Train Epoch: 4 [160/2166 (7%)]\t Average Loss: 0.000063\nUnlabeled examples trained on : 141\n[16/Nov/2020 22:41:22] INFO - Unlabeled Train Epoch: 4 [240/2166 (11%)]\t Average Loss: 0.000458\nUnlabeled examples trained on : 194\n[16/Nov/2020 22:41:31] INFO - Unlabeled Train Epoch: 4 [320/2166 (15%)]\t Average Loss: 0.000149\nUnlabeled examples trained on : 245\n[16/Nov/2020 22:41:39] INFO - Unlabeled Train Epoch: 4 [400/2166 (18%)]\t Average Loss: 0.002204\nUnlabeled examples trained on : 299\n[16/Nov/2020 22:41:48] INFO - Unlabeled Train Epoch: 4 [480/2166 (22%)]\t Average Loss: 0.000104\nUnlabeled examples trained on : 361\n","name":"stdout"},{"output_type":"stream","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6d2dbc6560>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n    self._shutdown_workers()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 140, in join\n    res = self._popen.wait(timeout)\n  File \"/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n  File \"/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n    pid, sts = os.waitpid(self.pid, flag)\nKeyboardInterrupt: \n","name":"stderr"},{"output_type":"stream","text":"[16/Nov/2020 22:42:05] INFO - Unlabeled Train Epoch: 4 [640/2166 (30%)]\t Average Loss: 0.000110\nUnlabeled examples trained on : 486\n[16/Nov/2020 22:42:14] INFO - Unlabeled Train Epoch: 4 [720/2166 (33%)]\t Average Loss: 0.000070\nUnlabeled examples trained on : 547\n[16/Nov/2020 22:42:23] INFO - Unlabeled Train Epoch: 4 [800/2166 (37%)]\t Average Loss: 0.008487\nUnlabeled examples trained on : 613\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%run evaluate.py --model vit --RUN_ID 62c81 --cfg vit_large_patch16_224 --experiment semi_supervized_experiment --data cropped_birds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%run filtered --proba 0.90","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ./..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -r bird_classification/confident90_filtered_cropped_NAbirds.zip bird_classification/confident90_filtered_cropped_NAbirds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.getcwd()\n#os.chdir(r'kaggle/working/bird_classification')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nout = FileLink(r'bird_classification/confident90_filtered_cropped_NAbirds.zip')\ndisplay(out)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a666ff79-9f5f-4584-a35d-835564bda9ed","_cell_guid":"5d7f4175-61a0-48b1-9278-921a4ea19d89","trusted":true},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}